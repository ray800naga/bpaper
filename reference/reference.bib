# 小池さんから頂いた感情分析のサーベイ
@article{emotion_analysis_survay,
  title    = {Vector based sentiment and emotion analysis from text: A survey},
  journal  = {Engineering Applications of Artificial Intelligence},
  volume   = {113},
  pages    = {104922},
  year     = {2022},
  issn     = {0952-1976},
  doi      = {https://doi.org/10.1016/j.engappai.2022.104922},
  url      = {https://www.sciencedirect.com/science/article/pii/S0952197622001452},
  author   = {Hande {Aka Uymaz} and Senem {Kumova Metin}},
  keywords = {Emotion, Sentiment, Vector space, Embedding, Emotion enriched vectors},
  abstract = {As a primary means of communication, texts are used to implicitly or explicitly reflect emotions. Emotion or sentiment detection from text has emerged as an important and expanding research area to more clearly understand the actual feelings of humans. Most of the word representation models, such as Word2Vec or GloVe, project the words in vector space such that if words have similar context, then their representations are also very similar. However, according to the recent studies, this approach limits the success of studies in areas such as emotion detection. For instance, love and happy are emotionally similar words, but they may have a lower similarity score than emotionally dissimilar word such as happy and sad which have high co-occurrence frequency, as they are in similar contexts. Recently, researchers propose some methods based on the addition of emotional or sentimental information to the original word vectors. These have improved the vector representation of words and achieved better results in emotion detection or classification tasks. In this survey, we analyze in detail such recent text-based studies in the literature. We summarize their methods used, emotion models, data sources, findings, and performances.}
}

# ekmanの感情モデル
@article{ekman,
  author    = { Paul   Ekman },
  title     = {An argument for basic emotions},
  journal   = {Cognition and Emotion},
  volume    = {6},
  number    = {3-4},
  pages     = {169-200},
  year      = {1992},
  publisher = {Routledge},
  doi       = {10.1080/02699939208411068},
  url       = { 
               https://doi.org/10.1080/02699939208411068
               },
  eprint    = {  
               https://doi.org/10.1080/02699939208411068
               }
}

# BERTの元論文
@misc{BERT,
  doi       = {10.48550/ARXIV.1810.04805},
  url       = {https://arxiv.org/abs/1810.04805},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

# Plutchikの感情モデル
@article{plutchik,
  author  = {Robert Plutchik},
  title   = {A psychoevolutionary theory of emotions},
  journal = {Social Science Information},
  volume  = {21},
  number  = {4-5},
  pages   = {529-553},
  year    = {1982},
  doi     = {10.1177/053901882021004003},
  url     = { 
             https://doi.org/10.1177/053901882021004003
             },
  eprint  = { 
             https://doi.org/10.1177/053901882021004003
             }
}

# 感情表現辞典
@book{kanjou_hyogen_jiten,
  author    = {中村 明},
  title     = {感情表現辞典},
  publisher = {東京堂出版},
  year      = {1993}
}


@article{emotion_model_1,
  author  = {Calvo, Rafael and Kim, Sunghwan},
  year    = {2012},
  month   = {09},
  pages   = {},
  title   = {Emotions in text: Dimensional and categorical models},
  volume  = {early view},
  journal = {Computational Intelligence},
  doi     = {10.1111/j.1467-8640.2012.00456.x}
}

@article{emotion_model_2,
  author  = {P S, SREEJA and G S, Mahalakshmi},
  year    = {2017},
  month   = {01},
  pages   = {651-657},
  title   = {Emotion Models: A Review},
  volume  = {10},
  journal = {International Journal of Control Theory and Applications}
}

@article{russell_2D,
  author  = {Russell, James},
  year    = {1980},
  month   = {12},
  pages   = {1161-1178},
  title   = {A Circumplex Model of Affect},
  volume  = {39},
  journal = {Journal of Personality and Social Psychology},
  doi     = {10.1037/h0077714}
}

@article{russell_3D,
  title    = {Evidence for a three-factor theory of emotions},
  journal  = {Journal of Research in Personality},
  volume   = {11},
  number   = {3},
  pages    = {273-294},
  year     = {1977},
  issn     = {0092-6566},
  doi      = {https://doi.org/10.1016/0092-6566(77)90037-X},
  url      = {https://www.sciencedirect.com/science/article/pii/009265667790037X},
  author   = {James A Russell and Albert Mehrabian},
  abstract = {Two studies provided evidence that three independent and bipolar dimensions, pleasure-displeasure, degree of arousal, and dominance-submissiveness, are both necessary and sufficient to adequately define emotional states. In one study with 200 subjects, 42 verbal-report emotion scales were explored in regression analyses as functions of the three dimensions plus a measure of acquiescence bias. Multiple correlation coefficients showed that almost all of the reliable variance in the 42 scales had been accounted for. The specific definitions provided by these equations were replicated in a second study that employed 300 subjects' ratings of 151 emotion-denoting terms on semantic differential-type scales.}
}

@misc{word2vec,
  doi       = {10.48550/ARXIV.1301.3781},
  url       = {https://arxiv.org/abs/1301.3781},
  author    = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year      = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{glove,
  author    = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title     = {GloVe: Global Vectors for Word Representation},
  year      = {2014},
  pages     = {1532--1543},
  url       = {http://www.aclweb.org/anthology/D14-1162}
}

@article{takeuchi,
  title   = {単語の持つ感情推定法の提案と単語感情辞書の構築},
  author  = {武内 達哉，萩原 将文},
  journal = {日本感性工学会論文誌},
  volume  = {18},
  number  = {4},
  pages   = {273-278},
  year    = {2019},
  doi     = {10.5057/jjske.TJSKE-D-18-00104}
}

@inproceedings{mecab,
  title     = {Applying Conditional Random Fields to {J}apanese Morphological Analysis},
  author    = {Kudo, Taku  and
               Yamamoto, Kaoru  and
               Matsumoto, Yuji},
  booktitle = {Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing},
  month     = jul,
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-3230},
  pages     = {230--237}
}

@misc{attention,
  doi       = {10.48550/ARXIV.1706.03762},
  url       = {https://arxiv.org/abs/1706.03762},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Attention Is All You Need},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{pytorch_advanced,
  author    = {小川 雄太郎},
  title     = {つくりながら学ぶ! PyTorchによる発展ディープラーニング},
  publisher = {マイナビ出版},
  year      = {2019}
}

@article{spin_kyokusei,
  author    = {高村 大也，乾 孝司，奥村 学},
  title     = {スピンモデルによる単語の感情極性抽出},
  journal   = {情報処理学会論文誌},
  issn      = {1882-7764},
  publisher = {一般社団法人情報処理学会},
  year      = {2006},
  month     = {02},
  volume    = {47},
  number    = {2},
  pages     = {627-637},
  url       = {https://cir.nii.ac.jp/crid/1050001337882589440}
}

@inproceedings{kajiwara-wrime,
  title     = {{WRIME}: A New Dataset for Emotional Intensity Estimation with Subjective and Objective Annotations},
  author    = {Kajiwara, Tomoyuki  and
               Chu, Chenhui  and
               Takemura, Noriko  and
               Nakashima, Yuta  and
               Nagahara, Hajime},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.naacl-main.169},
  doi       = {10.18653/v1/2021.naacl-main.169},
  pages     = {2095--2104},
  abstract  = {We annotate 17,000 SNS posts with both the writer{'}s subjective emotional intensity and the reader{'}s objective one to construct a Japanese emotion analysis dataset. In this study, we explore the difference between the emotional intensity of the writer and that of the readers with this dataset. We found that the reader cannot fully detect the emotions of the writer, especially anger and trust. In addition, experimental results in estimating the emotional intensity show that it is more difficult to estimate the writer{'}s subjective labels than the readers{'}. The large gap between the subjective and objective emotions imply the complexity of the mapping from a post to the subjective emotion intensities, which also leads to a lower performance with machine learning models.}
}

@misc{Adam,
  doi       = {10.48550/ARXIV.1412.6980},
  url       = {https://arxiv.org/abs/1412.6980},
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{wikipedia,
  title     = {Wikipedia 日本語版},
  publisher = {Wikipedia},
  note      = {\url{https://ja.wikipedia.org/wiki/メインページ}}
}

@inproceedings{wiki-40b,
title	= {Wiki-40B: Multilingual Language Model Dataset},
author	= {Mandy Guo and Zihang Dai and Denny Vrandecic and Rami Al-Rfou},
year	= {2020},
URL	= {http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.296.pdf},
booktitle	= {LREC 2020}
}

@misc{huggingface,
  title     = {Hugging Face},
  publisher = {Hugging Face},
  note      = {\url{https://huggingface.co/}}
}

@misc{cl-tohoku,
  title     = {cl-tohoku/bert-base-japanese-whole-word-masking},
  publisher = {Hugging Face},
  note      = {\url{https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking}}
}

@article{EZR,
author = {Kanda, Yoshinobu},
year = {2012},
month = {12},
pages = {},
title = {Kanada Y. Investigation of the freely-available easy-to-use software “EZR” (Easy R) for medical statistics. Bone Marrow Transplant. 2013;48:452-8},
volume = {48},
journal = {Bone marrow transplantation},
doi = {10.1038/bmt.2012.244}
}


@InProceedings{relu,
  title = 	 {Deep Sparse Rectifier Neural Networks},
  author = 	 {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {315--323},
  year = 	 {2011},
  editor = 	 {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
  url = 	 {https://proceedings.mlr.press/v15/glorot11a.html},
  abstract = 	 {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.}
}

@article{shapiro_wilk_test,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2333709},
 author = {S. S. Shapiro and M. B. Wilk},
 journal = {Biometrika},
 number = {3/4},
 pages = {591--611},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {An Analysis of Variance Test for Normality (Complete Samples)},
 urldate = {2023-01-19},
 volume = {52},
 year = {1965}
}

@article{kruskal_wallis_test,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2280779},
 abstract = {Given C samples, with ni observations in the ith sample, a test of the hypothesis that the samples are from the same population may be made by ranking the observations from from 1 to $\Sum n_i$ (giving each observation in a group of ties the mean of the ranks tied for), finding the C sums of ranks, and computing a statistic H. Under the stated hypothesis, H is distributed approximately as χ2(C - 1), unless the samples are too small, in which case special approximations or exact tables are provided. One of the most important applications of the test is in detecting differences among the population means.},
 author = {William H. Kruskal and W. Allen Wallis},
 journal = {Journal of the American Statistical Association},
 number = {260},
 pages = {583--621},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Use of Ranks in One-Criterion Variance Analysis},
 urldate = {2023-01-19},
 volume = {47},
 year = {1952}
}

@article{bartlett_test,
 ISSN = {00804630},
 URL = {http://www.jstor.org/stable/96803},
 author = {M. S. Bartlett},
 journal = {Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences},
 number = {901},
 pages = {268--282},
 publisher = {The Royal Society},
 title = {Properties of Sufficiency and Statistical Tests},
 urldate = {2023-01-19},
 volume = {160},
 year = {1937}
}

@article{bonferroni,
author = { Olive   Jean   Dunn },
title = {Multiple Comparisons among Means},
journal = {Journal of the American Statistical Association},
volume = {56},
number = {293},
pages = {52-64},
year  = {1961},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1961.10482090},
URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1961.10482090
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1961.10482090
}
}